{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions and Notations\n",
    "\n",
    "* $x^{(i)}$ input variables/features and  the space of all such $x^{(i)}$ is $X$\n",
    "* $y^{(i)}$ output/target variable that we are trying to predict and the space of all such $y^{(i)}$ is $Y$\n",
    "* A pair $(x^{(i)},y^{(i)})$ is called a training example and the dataset we will be using to learn - a list of $n$ training examples $ \\{(x^{(i)},y^{(i)});i=1,2,...,n\\} $ - is called a training set\n",
    "* the superscript $“(i)”$ in the notation is simply an index into the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Problem\n",
    "\n",
    "\n",
    "* The goal is, given a training set, to learn a function $ h: X \\mapsto Y$ so that $h(x)$ is a “good” predictor for the corresponding value of $y$. For historical reasons, this function h is called a hypothesis.\n",
    "\n",
    "* If  the target variable is continous ,the learning problem is **regression** \n",
    "* When y can take on only a small number of discrete values,the learning problem is **classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We need to know functions/hypotheses $h$.An initial choice can be approximating $y$ as a linear function of $x$: $$ h_{\\theta}(x)=\\theta_{0}+\\theta_{1}x_{1}+\\theta_{2}x_{2}$$ (if we choose only two features)\n",
    "\n",
    "* $\\theta_{i}$'s are **parameters/weight** parametrizing the space of linear functions mapping from $X$ to $Y$.\n",
    "* Using the convention $x_{0}=1$(**Intercept term**),so that $$h(x)=\\sum_{i=0}^{d}\\theta_{i}x_{i}=\\theta^{T}x,$$\n",
    "$\\theta$ and $x$ are vectors and $d$ is the number of input variables (not counting $x_{0}$)\n",
    "\n",
    "* For a training set,we have to pick or  learn the parameters $\\theta,$ so that we can predict $y$.\n",
    "* One reasonable method seems to be to make $h(x)$ cloase to y,for the training examples.To formalize this, we will define a function that measures, for each value of the θ’s, how close the $h(x^{(i)})'$ s are to the corrsponding $y^{(i)}$'s.\n",
    "\n",
    "* We  define **Cost/Loss** function: $$J(\\theta)=\\frac{1}{2}\\sum_{i=1}^{n}(h_{\\theta}(x^{(i)})-y^{(i)})^{2},$$this is the least squares-cost function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LMS Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Given:  $(x^{(i)},y^{(i)}),$ $i=1,...,n$\n",
    "* Minimize: $J(\\theta)=\\frac{1}{2}\\sum_{i=1}^{n}(h_{\\theta}(x^{(i)})-y^{(i)})^{2}$\n",
    "\n",
    "* We want to choose θ so as to minimize $J(\\theta)$\n",
    "\n",
    "* We can use the gradient descent algorithm that starts with some “initial guess” for $\\theta$, and that repeatedly changes $\\theta$ to make $J(\\theta)$ smaller, until hopefully we converge to a value of\n",
    "$\\theta$ that minimizes $J(\\theta)$.\n",
    "\n",
    "* The **Gradient Descent ** algorithm,which starts from initial $\\theta,$ and repeatedly performs the update: $$\\theta_{j}:=\\theta_{j}-\\alpha \\frac{\\partial J( \\theta)}{\\partial \\theta_{j}} ,$$ until some condition is met.\n",
    "This update is simultaneously performed for all values of  $j = 0, . . . , d$\n",
    "\n",
    "* $\\alpha$ is called the learning rate. This is a very natural algorithm that repeatedly takes a step in the direction of steepest decrease of $J$.\n",
    "\n",
    "    * We need to find the partial derivative in the quation,so that we can implement the algorithm.For a single training example $(x,y).$ We have:$$\\frac{\\partial J( \\theta)}{\\partial \\theta_{j}}=\\frac{\\partial}{\\partial \\theta_{j}}\\frac{1}{2}(h_{\\theta}(x)-y)^{2}$$\n",
    "$$=2.\\frac{1}{2}(h_{\\theta}(x)-y).\\frac{\\partial}{\\partial \\theta_{j}}(h_{\\theta}(x)-y)$$\n",
    "$$=(h_{\\theta}(x)-y).\\frac{\\partial}{\\partial \\theta_{j}} (\\sum _{i=0}^{d}\\theta_{i}x_{i}-y)$$\n",
    "$$=(h_{\\theta}(x)-y)x_{j}$$\n",
    "\n",
    "* for a single training example,this gives the update rule:$$\\theta_{j}:=\\theta_{j}+\\alpha(y^{(i)}-h_{\\theta}(x^{(i)}))x_{j}^{(i)},$$this rule is called **LMS**(Least Mean Square)update rule.\n",
    "\n",
    "For a training set,\n",
    "* Repeat until convergence {$$\\theta_{j}:=\\theta_{j}+\\alpha\\sum_{i=1}^{n}(y^{(i)}-h_{\\theta}(x^{(i)}))x_{j}^{(i)}$$ ( for every $j$) .}\n",
    "\n",
    "* $J$ being convex quadratic function,the optimization here for linear regression has only one global, and no other local, optima; thus gradient descent always converges (assuming the learning rate α is not too large) to the global minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
